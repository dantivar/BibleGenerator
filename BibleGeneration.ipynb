{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BibleGeneration",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ekp7Gnp1loyA",
        "colab_type": "text"
      },
      "source": [
        "# Biblical quotes generator\n",
        "The following is an biblical text generator that was trained using the first 1000 quotes of America's Standard Bible.\n",
        "To upload files uncomment line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ppZ8CNzOxfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import csv\n",
        "import os\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5jCz4a0PTfF",
        "colab_type": "code",
        "outputId": "4f9fd469-c207-4254-d15e-7a2e79c097ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#open csv file\n",
        "with open(\"t_asv.csv\") as file:\n",
        "  csvreader = csv.reader(file, delimiter=\",\")\n",
        "  quotes = []\n",
        "  for row in csvreader:\n",
        "    quotes.append(row[4])\n",
        "file.close()\n",
        "#lower corpus\n",
        "quotes = [quote.lower() for quote in quotes]\n",
        "#print number of quotes\n",
        "print(len(quotes))\n",
        "#print an example of a quote\n",
        "print(quotes[12])\n",
        "#select training size of 1000\n",
        "quotes = quotes[:1000]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31104\n",
            "and the earth brought forth grass, herbs yielding seed after their kind, and trees bearing fruit, wherein is the seed thereof, after their kind: and god saw that it was good.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i6kHtgUobHy",
        "colab_type": "code",
        "outputId": "0b656bee-9b0f-421b-bdb9-f1cce2e9fc69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#create tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "#create word_index and registe words on quotes\n",
        "tokenizer.fit_on_texts(quotes)\n",
        "#print total number of words\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(total_words)\n",
        "\n",
        "#convert text to sequences\n",
        "input_sequences = []\n",
        "for line in quotes:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)\n",
        "\n",
        "#get maximum sequence length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "print(input_sequences.shape)\n",
        "\n",
        "#prepare dataset with labels and inputs\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "\n",
        "#convert labels to categorical representation\n",
        "label = tf.keras.utils.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1946\n",
            "(23542, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlPSZa_cssgh",
        "colab_type": "code",
        "outputId": "0d27f021-fa03-44b1-8445-e2f4b2fbf033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "#create model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Embedding(total_words, 100, input_length=max_sequence_len-1),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150, return_sequences=True)),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.LSTM(150),\n",
        "  tf.keras.layers.Dense(total_words/2, activation='relu'),\n",
        "  tf.keras.layers.Dense(total_words, activation='softmax')]\n",
        ")\n",
        "\n",
        "#compile and print model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 63, 100)           194600    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 63, 300)           301200    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 63, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 150)               270600    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 973)               146923    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1946)              1895404   \n",
            "=================================================================\n",
            "Total params: 2,808,727\n",
            "Trainable params: 2,808,727\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sQCrw_Uxg6V",
        "colab_type": "code",
        "outputId": "55a207fd-4ea5-477d-e31a-d7c04f6c0671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#use callback for plus 90% accuracy and start training. It took about 3 hours of training to get 85% accuracy\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if logs.get('acc')>0.9:\n",
        "      self.model.stop_training=True\n",
        "\n",
        "myCallback = myCallback()\n",
        "history = model.fit(predictors, label, epochs=100, verbose=1, callbacks=[myCallback])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "23542/23542 [==============================] - 253s 11ms/sample - loss: 5.6290 - acc: 0.0910\n",
            "Epoch 2/100\n",
            "23542/23542 [==============================] - 250s 11ms/sample - loss: 5.0294 - acc: 0.1425\n",
            "Epoch 3/100\n",
            "23542/23542 [==============================] - 250s 11ms/sample - loss: 4.7187 - acc: 0.1642\n",
            "Epoch 4/100\n",
            "23542/23542 [==============================] - 251s 11ms/sample - loss: 4.4569 - acc: 0.1846\n",
            "Epoch 5/100\n",
            "23542/23542 [==============================] - 252s 11ms/sample - loss: 4.2613 - acc: 0.1988\n",
            "Epoch 6/100\n",
            "23542/23542 [==============================] - 254s 11ms/sample - loss: 4.0790 - acc: 0.2109\n",
            "Epoch 7/100\n",
            "23542/23542 [==============================] - 256s 11ms/sample - loss: 3.9033 - acc: 0.2278\n",
            "Epoch 8/100\n",
            "23542/23542 [==============================] - 254s 11ms/sample - loss: 3.7290 - acc: 0.2433\n",
            "Epoch 9/100\n",
            "23542/23542 [==============================] - 256s 11ms/sample - loss: 3.5643 - acc: 0.2565\n",
            "Epoch 10/100\n",
            "23542/23542 [==============================] - 254s 11ms/sample - loss: 3.4042 - acc: 0.2693\n",
            "Epoch 11/100\n",
            "23542/23542 [==============================] - 252s 11ms/sample - loss: 3.2423 - acc: 0.2849\n",
            "Epoch 12/100\n",
            "23542/23542 [==============================] - 253s 11ms/sample - loss: 3.0833 - acc: 0.2999\n",
            "Epoch 13/100\n",
            "23542/23542 [==============================] - 251s 11ms/sample - loss: 2.9304 - acc: 0.3154\n",
            "Epoch 14/100\n",
            "23542/23542 [==============================] - 251s 11ms/sample - loss: 2.7750 - acc: 0.3359\n",
            "Epoch 15/100\n",
            "23542/23542 [==============================] - 252s 11ms/sample - loss: 2.6324 - acc: 0.3579\n",
            "Epoch 16/100\n",
            "23542/23542 [==============================] - 257s 11ms/sample - loss: 2.4892 - acc: 0.3763\n",
            "Epoch 17/100\n",
            "23542/23542 [==============================] - 257s 11ms/sample - loss: 2.3351 - acc: 0.4080\n",
            "Epoch 18/100\n",
            "23542/23542 [==============================] - 257s 11ms/sample - loss: 2.1977 - acc: 0.4289\n",
            "Epoch 19/100\n",
            "23542/23542 [==============================] - 259s 11ms/sample - loss: 2.0607 - acc: 0.4557\n",
            "Epoch 20/100\n",
            "23542/23542 [==============================] - 258s 11ms/sample - loss: 1.9351 - acc: 0.4835\n",
            "Epoch 21/100\n",
            "23542/23542 [==============================] - 262s 11ms/sample - loss: 1.8068 - acc: 0.5094\n",
            "Epoch 22/100\n",
            "23542/23542 [==============================] - 256s 11ms/sample - loss: 1.6905 - acc: 0.5372\n",
            "Epoch 23/100\n",
            "23542/23542 [==============================] - 259s 11ms/sample - loss: 1.5871 - acc: 0.5604\n",
            "Epoch 24/100\n",
            "23542/23542 [==============================] - 258s 11ms/sample - loss: 1.4762 - acc: 0.5900\n",
            "Epoch 25/100\n",
            "23542/23542 [==============================] - 255s 11ms/sample - loss: 1.3786 - acc: 0.6161\n",
            "Epoch 26/100\n",
            "23542/23542 [==============================] - 256s 11ms/sample - loss: 1.2957 - acc: 0.6350\n",
            "Epoch 27/100\n",
            "23542/23542 [==============================] - 256s 11ms/sample - loss: 1.2034 - acc: 0.6598\n",
            "Epoch 28/100\n",
            "23542/23542 [==============================] - 254s 11ms/sample - loss: 1.1218 - acc: 0.6824\n",
            "Epoch 29/100\n",
            "23542/23542 [==============================] - 255s 11ms/sample - loss: 1.0505 - acc: 0.7074\n",
            "Epoch 30/100\n",
            "23542/23542 [==============================] - 255s 11ms/sample - loss: 0.9840 - acc: 0.7211\n",
            "Epoch 31/100\n",
            "23542/23542 [==============================] - 257s 11ms/sample - loss: 0.9162 - acc: 0.7400\n",
            "Epoch 32/100\n",
            "23542/23542 [==============================] - 256s 11ms/sample - loss: 0.8796 - acc: 0.7493\n",
            "Epoch 33/100\n",
            "23542/23542 [==============================] - 252s 11ms/sample - loss: 0.8151 - acc: 0.7690\n",
            "Epoch 34/100\n",
            "23542/23542 [==============================] - 255s 11ms/sample - loss: 0.7747 - acc: 0.7785\n",
            "Epoch 35/100\n",
            "23542/23542 [==============================] - 254s 11ms/sample - loss: 0.7426 - acc: 0.7895\n",
            "Epoch 36/100\n",
            "23542/23542 [==============================] - 253s 11ms/sample - loss: 0.7075 - acc: 0.7983\n",
            "Epoch 37/100\n",
            "23542/23542 [==============================] - 254s 11ms/sample - loss: 0.6717 - acc: 0.8115\n",
            "Epoch 38/100\n",
            "23542/23542 [==============================] - 255s 11ms/sample - loss: 0.6365 - acc: 0.8194\n",
            "Epoch 39/100\n",
            "23542/23542 [==============================] - 254s 11ms/sample - loss: 0.6267 - acc: 0.8244\n",
            "Epoch 40/100\n",
            "23542/23542 [==============================] - 253s 11ms/sample - loss: 0.5952 - acc: 0.8323\n",
            "Epoch 41/100\n",
            "23542/23542 [==============================] - 253s 11ms/sample - loss: 0.5831 - acc: 0.8371\n",
            "Epoch 42/100\n",
            "23542/23542 [==============================] - 250s 11ms/sample - loss: 0.5596 - acc: 0.8435\n",
            "Epoch 43/100\n",
            "23542/23542 [==============================] - 252s 11ms/sample - loss: 0.5376 - acc: 0.8534\n",
            "Epoch 44/100\n",
            "23542/23542 [==============================] - 253s 11ms/sample - loss: 0.5423 - acc: 0.8479\n",
            "Epoch 45/100\n",
            "23542/23542 [==============================] - 253s 11ms/sample - loss: 0.5272 - acc: 0.8523\n",
            "Epoch 46/100\n",
            "23542/23542 [==============================] - 255s 11ms/sample - loss: 0.5171 - acc: 0.8552\n",
            "Epoch 47/100\n",
            "  352/23542 [..............................] - ETA: 4:10 - loss: 0.4828 - acc: 0.8608"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6c499547aa47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmyCallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmyCallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePnaFiMWfN_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#uncomment to save the model\n",
        "#model.save('bibleModel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26_lFTFWxwNg",
        "colab_type": "code",
        "outputId": "d0b91988-4af1-4519-89c5-febd87c6f461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#generate text\n",
        "seed_text = \"He gives power to the weak and strength to the powerless\"\n",
        "next_words = 100\n",
        "print(max_sequence_len)\n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted = model.predict_classes(token_list, verbose=0)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n",
            "He gives power to the weak and strength to the powerless sheep and go and now lest he put forth his trained men born in his house three hundred and eighteen and pursued as far against child for now i know that thou fearest unto her thou art a fair woman to look upon the death of the child and she sat over against him and lifted up her voice and wept at the field and breathed with him at the land of canaan even with them saying he hath heard the voice of whence god hath seen mine affliction and the labor of my hands and rebuked thee yesternight and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-QuI6fb63DY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6a615022-5b5f-4826-f789-772d504f5038"
      },
      "source": [
        "#import os\n",
        "#print(os.getcwd())\n",
        "#print(os.listdir('./checkpoints'))\n",
        "#print('-------')\n",
        "#print(os.listdir('.'))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "['biblegc.data-00001-of-00002', 'checkpoint', 'biblegc.index', 'biblegc.data-00000-of-00002']\n",
            "-------\n",
            "['.config', 't_asv.csv', 'checkpoints', 'bibleModel.h5', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFOiyrynYgA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#uncomment to download model. Only works if the model was previously saved\n",
        "\n",
        "files.download('bibleModel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7c_zQJ5kpzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}